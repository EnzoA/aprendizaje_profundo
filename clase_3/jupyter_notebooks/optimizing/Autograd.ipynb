{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n",
    "\n",
    "Ver detalles del mecanísmo de autograd de PyTorch en éste [link](https://pytorch.org/docs/stable/notes/autograd.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a 2x2 tensor with gradient-accumulation capabilities\n",
    "x = torch.tensor([[1, 2], [3, 4]], requires_grad=True, dtype=torch.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  0.],\n",
      "        [ 1.,  2.]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x - 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SubBackward0 object at 0x000001AFD589DF70>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SubBackward0 at 0x1afd1787730>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AccumulateGrad at 0x1afd1781220>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn.next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn.next_functions[0][0].variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  0.],\n",
      "        [ 3., 12.]], grad_fn=<MulBackward0>)\n",
      "tensor(4.5000, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "a = z.mean()  # average\n",
    "\n",
    "print(z)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchviz\n",
      "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\lautaro\\anaconda3\\lib\\site-packages (from torchviz) (1.7.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\lautaro\\anaconda3\\lib\\site-packages (from torchviz) (0.16)\n",
      "Requirement already satisfied: future in c:\\users\\lautaro\\anaconda3\\lib\\site-packages (from torch->torchviz) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\lautaro\\anaconda3\\lib\\site-packages (from torch->torchviz) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\lautaro\\anaconda3\\lib\\site-packages (from torch->torchviz) (0.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\lautaro\\anaconda3\\lib\\site-packages (from torch->torchviz) (1.19.2)\n",
      "Building wheels for collected packages: torchviz\n",
      "  Building wheel for torchviz (setup.py): started\n",
      "  Building wheel for torchviz (setup.py): finished with status 'done'\n",
      "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4154 sha256=c2b9628cbaa4804f178976ec4dbace2a411249ef8b7999661d2e828da8911c4b\n",
      "  Stored in directory: c:\\users\\lautaro\\appdata\\local\\pip\\cache\\wheels\\05\\7d\\1b\\8306781244e42ede119edbb053bdcda1c1f424ca226165a417\n",
      "Successfully built torchviz\n",
      "Installing collected packages: torchviz\n",
      "Successfully installed torchviz-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchviz\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"109pt\" height=\"381pt\"\r\n",
       " viewBox=\"0.00 0.00 109.00 381.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 377)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-377 105,-377 105,4 -4,4\"/>\r\n",
       "<!-- 1854713704832 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>1854713704832</title>\r\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,-0 77.5,-0 77.5,-31\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\r\n",
       "</g>\r\n",
       "<!-- 1854581198032 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1854581198032</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"98,-86 3,-86 3,-67 98,-67 98,-86\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 1854581198032&#45;&gt;1854713704832 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>1854581198032&#45;&gt;1854713704832</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.7943C50.5,-60.0669 50.5,-50.404 50.5,-41.3425\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.0001,-41.1932 50.5,-31.1933 47.0001,-41.1933 54.0001,-41.1932\"/>\r\n",
       "</g>\r\n",
       "<!-- 1854581198176 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>1854581198176</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 1854581198176&#45;&gt;1854581198032 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>1854581198176&#45;&gt;1854581198032</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.748C50.5,-114.802 50.5,-104.845 50.5,-96.1349\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.0001,-96.089 50.5,-86.089 47.0001,-96.0891 54.0001,-96.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 1854581198080 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>1854581198080</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-196 6,-196 6,-177 95,-177 95,-196\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 1854581198080&#45;&gt;1854581198176 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1854581198080&#45;&gt;1854581198176</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.748C50.5,-169.802 50.5,-159.845 50.5,-151.135\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.0001,-151.089 50.5,-141.089 47.0001,-151.089 54.0001,-151.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 1854645237552 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>1854645237552</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-251 6,-251 6,-232 95,-232 95,-251\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 1854645237552&#45;&gt;1854581198080 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1854645237552&#45;&gt;1854581198080</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M45.3337,-231.748C43.8407,-224.802 43.4034,-214.845 44.0215,-206.135\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.5084,-206.466 45.369,-196.089 40.5705,-205.535 47.5084,-206.466\"/>\r\n",
       "</g>\r\n",
       "<!-- 1854645237552&#45;&gt;1854581198080 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>1854645237552&#45;&gt;1854581198080</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M55.6663,-231.748C57.1593,-224.802 57.5966,-214.845 56.9785,-206.135\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"60.4295,-205.535 55.631,-196.089 53.4916,-206.466 60.4295,-205.535\"/>\r\n",
       "</g>\r\n",
       "<!-- 1854645211680 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>1854645211680</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-306 0,-306 0,-287 101,-287 101,-306\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 1854645211680&#45;&gt;1854645237552 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>1854645211680&#45;&gt;1854645237552</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.748C50.5,-279.802 50.5,-269.845 50.5,-261.135\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.0001,-261.089 50.5,-251.089 47.0001,-261.089 54.0001,-261.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 1854649220160 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>1854649220160</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"80,-373 21,-373 21,-342 80,-342 80,-373\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\"> (2, 2)</text>\r\n",
       "</g>\r\n",
       "<!-- 1854649220160&#45;&gt;1854645211680 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>1854649220160&#45;&gt;1854645211680</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-341.916C50.5,-334.221 50.5,-324.688 50.5,-316.43\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.0001,-316.249 50.5,-306.249 47.0001,-316.249 54.0001,-316.249\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1afcda74af0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Create tensors.\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "\n",
    "# Compute gradients.\n",
    "y.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print(x.grad)    # x.grad = 2 \n",
    "print(w.grad)    # w.grad = 1 \n",
    "print(b.grad)    # b.grad = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop --> equivalente a a.backward(torch.tensor([1.0]))\n",
    "a.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "# da/dx:\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-f02a655509eb>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  print(y.grad)\n"
     ]
    }
   ],
   "source": [
    "# da/dy:\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -452.7864,   -56.4709, -1476.9196], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Dynamic graphs!\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "i = 0\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "    i += 1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autograd --> Jacobianos J[]*v = dv/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "# If we don't run backward on a scalar we need to specify the grad_output\n",
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# Both x and w that allows gradient accumulation\n",
    "x = torch.arange(1., n + 1, requires_grad=True)\n",
    "w = torch.ones(n, requires_grad=True)\n",
    "z = w @ x\n",
    "z.backward()\n",
    "print(x.grad, w.grad, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# Only w that allows gradient accumulation\n",
    "x = torch.arange(1., n + 1)\n",
    "w = torch.ones(n, requires_grad=True)\n",
    "z = w @ x\n",
    "z.backward()\n",
    "print(x.grad, w.grad, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError!!! >:[\n",
      "element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1., n + 1)\n",
    "w = torch.ones(n, requires_grad=True)\n",
    "\n",
    "# Regardless of what you do in this context, all torch tensors will not have gradient accumulation\n",
    "with torch.no_grad():\n",
    "    z = w @ x\n",
    "\n",
    "try:\n",
    "    z.backward()  # PyTorch will throw an error here, since z has no grad accum.\n",
    "except RuntimeError as e:\n",
    "    print('RuntimeError!!! >:[')\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación en ANNs"
   ]
  },
  {
   "attachments": {
    "comp-graph.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![comp-graph.png](attachment:comp-graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x000001AFD59887F0>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward object at 0x000001AFD59888B0>\n"
     ]
    }
   ],
   "source": [
    "print('Gradient function for z =', z.grad_fn)\n",
    "print('Gradient function for loss =', loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1926, 0.0049, 0.1790],\n",
      "        [0.1926, 0.0049, 0.1790],\n",
      "        [0.1926, 0.0049, 0.1790],\n",
      "        [0.1926, 0.0049, 0.1790],\n",
      "        [0.1926, 0.0049, 0.1790]])\n",
      "tensor([0.1926, 0.0049, 0.1790])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deshabilitar autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0,\n",
    "                    3.0, -4.0, 6.0, 13.0, 21.0])\n",
    "t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9,\n",
    "                    33.9, 21.8, 48.4, 60.4, 68.4])\n",
    "t_un = 0.1 * t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w * t_u + b\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "\n",
    "params.grad is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(model(t_u, *params), t_c)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4517.2969,   82.6000])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.grad is not None:\n",
    "    params.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if params.grad is not None:  # <1>\n",
    "            params.grad.zero_()\n",
    "        \n",
    "        t_p = model(t_u, *params) \n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Cómo reemplaza\n",
    "        with torch.no_grad():  # <2>\n",
    "            params -= learning_rate * params.grad\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.860115\n",
      "Epoch 1000, Loss 3.828538\n",
      "Epoch 1500, Loss 3.092191\n",
      "Epoch 2000, Loss 2.957698\n",
      "Epoch 2500, Loss 2.933134\n",
      "Epoch 3000, Loss 2.928648\n",
      "Epoch 3500, Loss 2.927830\n",
      "Epoch 4000, Loss 2.927679\n",
      "Epoch 4500, Loss 2.927652\n",
      "Epoch 5000, Loss 2.927647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3671, -17.3012], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    learning_rate = 1e-2, \n",
    "    params = torch.tensor([1.0, 0.0], requires_grad=True), # <1> \n",
    "    t_u = t_un, # <2> \n",
    "    t_c = t_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
